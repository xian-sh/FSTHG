{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T16:22:37.675619Z",
     "end_time": "2025-05-09T16:22:37.737620Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T16:22:37.737620Z",
     "end_time": "2025-05-09T16:22:37.799622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current work dir: G:\\EEG_TAC\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_path = r\"G:\\EEG_TAC\"\n",
    "os.chdir(root_path)\n",
    "print(\"current work dir:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T16:22:37.801621Z",
     "end_time": "2025-05-09T16:22:49.774376Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "\n",
    "from utils import set_logging_config, dict_to_markdown, set_seed\n",
    "from datasets import DEAPDataset\n",
    "from datasets.transforms import (BandDifferentialEntropy, Compose, ToGrid, ToTensor, To2d,\n",
    "                                 Select, Binary, BaselineRemoval)\n",
    "from datasets.constants import DEAP_CHANNEL_LOCATION_DICT, DEAP_LOCATION_LIST, STANDARD_1005_CHANNEL_LOCATION_DICT, \\\n",
    "    STANDARD_1020_CHANNEL_LOCATION_DICT\n",
    "from model_selection import KFoldPerSubjectCrossTrial, KFoldPerSubjectGroupbyTrial, KFoldPerSubject\n",
    "\n",
    "from models.model import build_model\n",
    "from engine import train_model_per_subject, save_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T16:22:49.777376Z",
     "end_time": "2025-05-09T16:22:50.108304Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = \"deap\"\n",
    "label = \"arousal\"\n",
    "chunk_size = 128 * 4\n",
    "\n",
    "\n",
    "args = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"label\": label,  # valence\n",
    "    \"data_dir\": r'G:\\Data\\EEG-Data\\deap\\data_preprocessed_python',\n",
    "    \"feature_dir\": f\"./processed_data/{dataset_name}_{label}_{chunk_size}\",\n",
    "    \"chunk_size\": chunk_size,\n",
    "    \"results_dir\": \"./ckpts/\",\n",
    "    \"split_mode\": \"no_shuffle\",  # \"per_cross\"\n",
    "    \"subject_num\": 32,\n",
    "\n",
    "    \"model_name\": \"ERM\",\n",
    "    \"num_classes\": 2,\n",
    "    \"in_channel\": 32,\n",
    "    \"embed_size\": 64,   # best 64\n",
    "\n",
    "    # albation\n",
    "    \"graph_variant\": \"time_gcn\", # [time_gcn, time_cnn, time_att, fft_cnn, fft_att, fft_hyp]\n",
    "    \"use_wsd\": True,\n",
    "    \"use_dfhc\": True,\n",
    "    \"wavelet_level\": 2,  # [2,3,4,5]  # best 2\n",
    "    \"base_fun\": \"sine\", # [linear, gauss, sine]\n",
    "    \"graph_layer\": 2,  # [1,2,3,4]  # best 2\n",
    "    \"add_noise\": False,\n",
    "    \"noise_std\": 0.05,   # std\n",
    "\n",
    "    \"seed\": 42,\n",
    "    \"max_epochs\": 15,\n",
    "    \"batch_size\": 12,\n",
    "    \"kflod\": 10,\n",
    "    \"lr\": 0.0008,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T16:22:50.110305Z",
     "end_time": "2025-05-09T16:22:50.397411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-10 00:22:50,381] [main]  Args:\n",
      " |               | 0                                                                                                   |\n",
      "|:--------------|:----------------------------------------------------------------------------------------------------|\n",
      "| dataset_name  | deap                                                                                                |\n",
      "| label         | arousal                                                                                             |\n",
      "| data_dir      | G:\\Data\\EEG-Data\\deap\\data_preprocessed_python                                                      |\n",
      "| feature_dir   | ./processed_data/deap_arousal_512                                                                   |\n",
      "| chunk_size    | 512                                                                                                 |\n",
      "| results_dir   | ./ckpts/deap\\arousal\\no_shuffle_vartime_gcn_wsdon_dfhcon_wave2_basefunsine_layer2_kflod10_emb64_new |\n",
      "| split_mode    | no_shuffle                                                                                          |\n",
      "| subject_num   | 32                                                                                                  |\n",
      "| model_name    | ERM                                                                                                 |\n",
      "| num_classes   | 2                                                                                                   |\n",
      "| in_channel    | 32                                                                                                  |\n",
      "| embed_size    | 64                                                                                                  |\n",
      "| graph_variant | time_gcn                                                                                            |\n",
      "| use_wsd       | True                                                                                                |\n",
      "| use_dfhc      | True                                                                                                |\n",
      "| wavelet_level | 2                                                                                                   |\n",
      "| base_fun      | sine                                                                                                |\n",
      "| graph_layer   | 2                                                                                                   |\n",
      "| add_noise     | False                                                                                               |\n",
      "| noise_std     | 0.05                                                                                                |\n",
      "| seed          | 42                                                                                                  |\n",
      "| max_epochs    | 15                                                                                                  |\n",
      "| batch_size    | 12                                                                                                  |\n",
      "| kflod         | 10                                                                                                  |\n",
      "| lr            | 0.0008                                                                                              |\n",
      "| weight_decay  | 0.0001                                                                                              |\n",
      "| device        | cuda                                                                                                |\n"
     ]
    }
   ],
   "source": [
    "set_seed(args['seed'])\n",
    "\n",
    "log_dir = os.path.join(\n",
    "    args['results_dir'],\n",
    "    args['dataset_name'],\n",
    "    args['label'],\n",
    "    f\"{args['split_mode']}_var{args['graph_variant']}_wsd{'on' if args['use_wsd'] else 'off'}_dfhc{'on' if args['use_dfhc'] else 'off'}_wave{args['wavelet_level']}_basefun{args['base_fun']}_layer{args['graph_layer']}_kflod{args['kflod']}_emb{args['embed_size']}_new\"\n",
    ")\n",
    "# os.path.join(args['results_dir'], args['dataset_name'], args['label'], f\"{args['dataset_name']}_{args['label']}_{args['model_name']}_{args['split_mode']}_250116\")\n",
    "args[\"results_dir\"] = log_dir\n",
    "set_logging_config(log_dir)\n",
    "logger = logging.getLogger(\"main\")\n",
    "logger.info(f\" Args:\\n {dict_to_markdown(args)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2025-05-09T16:22:50.394412Z",
     "end_time": "2025-05-09T16:22:50.806505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-10 00:22:50,653] [torcheeg] ðŸ” | Detected cached processing results, reading cache from ./processed_data/deap_arousal_512.\n",
      "[2025-05-10 00:22:50,789] [main] Sample shape: torch.Size([1, 32, 512])\tTotal samples: 19200\n"
     ]
    }
   ],
   "source": [
    "dataset = DEAPDataset(io_path=args['feature_dir'], root_path=args['data_dir'], chunk_size=args[\"chunk_size\"],\n",
    "                      online_transform=Compose([To2d(), ToTensor()]),\n",
    "                      label_transform=Compose([Select(args['label']), Binary(5.0), ]),\n",
    "                      num_worker=0)\n",
    "\n",
    "logger.info(f\"Sample shape: {dataset[0][0].shape}\\tTotal samples: {len(dataset)}\")\n",
    "\n",
    "if args['split_mode'] == 'per_cross':\n",
    "    cv = KFoldPerSubjectCrossTrial(n_splits=args['kflod'], shuffle=True, split_path=os.path.join(log_dir, f\"split_kflod_{args['kflod']}\"))\n",
    "elif args['split_mode'] == 'per_groupby':\n",
    "    cv = KFoldPerSubjectGroupbyTrial(n_splits=args['kflod'], shuffle=False,\n",
    "                                     split_path=os.path.join(log_dir, f\"split_kflod_{args['kflod']}\"))\n",
    "elif args['split_mode'] == 'no_shuffle':\n",
    "    cv = KFoldPerSubject(n_splits=args['kflod'], shuffle=False, split_path=os.path.join(log_dir, f\"split_kflod_{args['kflod']}\"))\n",
    "elif args['split_mode'] == 'shuffle':\n",
    "    cv = KFoldPerSubject(n_splits=args['kflod'], shuffle=True, split_path=os.path.join(log_dir, f\"split_kflod_{args['kflod']}\"))\n",
    "else:\n",
    "    raise NameError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T16:00:30.053695Z",
     "end_time": "2025-05-09T16:06:59.299665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-10 00:28:06,912] [main] Model: ERM, Number of parameters: 0.2276 M\n",
      "[2025-05-10 00:28:06,913] [main] embed: 0.0021M\n",
      "[2025-05-10 00:28:06,913] [main] wavelet: 0.1852M\n",
      "[2025-05-10 00:28:06,914] [main] graph_conv: 0.0170M\n",
      "[2025-05-10 00:28:06,915] [main] base_conv: 0.0205M\n",
      "[2025-05-10 00:28:06,915] [main] base_scale: 0.0001M\n",
      "[2025-05-10 00:28:06,916] [main] classifier: 0.0026M\n",
      "[2025-05-10 00:28:06,917] [main] --------------------------------------------------\n",
      "[2025-05-10 00:28:06,918] [torcheeg] ðŸ“Š | Detected existing split of train and test set, use existing split from ./ckpts/deap\\arousal\\no_shuffle_vartime_gcn_wsdon_dfhcon_wave2_basefunsine_layer2_kflod10_emb64_new\\split_kflod_10.\n",
      "[2025-05-10 00:28:06,918] [torcheeg] ðŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "./processed_data/deap_arousal_512\\_record_0\\eeg: Not enough space",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 11\u001B[0m\n\u001B[0;32m      7\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_params\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39margs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m], weight_decay\u001B[38;5;241m=\u001B[39margs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 11\u001B[0m final_results_dict \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model_per_subject\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                            \u001B[49m\u001B[43msubject_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msubject_num\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_epochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_idx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\EEG_TAC\\engine.py:107\u001B[0m, in \u001B[0;36mtrain_model_per_subject\u001B[1;34m(model, dataset, optimizer, cv, subject_num, max_epochs, batch_size, device, logger, log_dir, sub_idx)\u001B[0m\n\u001B[0;32m    104\u001B[0m subject_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(log_dir, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubject_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m02d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    105\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(subject_dir, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 107\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j, (train_dataset, val_dataset) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(cv\u001B[38;5;241m.\u001B[39msplit(dataset, subject\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m02d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.dat\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[0;32m    108\u001B[0m     train_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    109\u001B[0m     val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mG:\\EEG_TAC\\model_selection.py:1838\u001B[0m, in \u001B[0;36mKFoldPerSubject.split\u001B[1;34m(self, dataset, subject)\u001B[0m\n\u001B[0;32m   1835\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m copy(dataset)\n\u001B[0;32m   1836\u001B[0m train_dataset\u001B[38;5;241m.\u001B[39minfo \u001B[38;5;241m=\u001B[39m train_info\n\u001B[1;32m-> 1838\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1839\u001B[0m test_dataset\u001B[38;5;241m.\u001B[39minfo \u001B[38;5;241m=\u001B[39m test_info\n\u001B[0;32m   1841\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m train_dataset, test_dataset\n",
      "File \u001B[1;32m~\\.conda\\envs\\eeg-env\\lib\\copy.py:84\u001B[0m, in \u001B[0;36mcopy\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     82\u001B[0m copier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__copy__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 84\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m reductor \u001B[38;5;241m=\u001B[39m dispatch_table\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reductor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mG:\\EEG_TAC\\datasets\\base.py:527\u001B[0m, in \u001B[0;36mBaseDataset.__copy__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    525\u001B[0m result\u001B[38;5;241m.\u001B[39meeg_io_router \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    526\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m record, eeg_io \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meeg_io_router\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 527\u001B[0m     result\u001B[38;5;241m.\u001B[39meeg_io_router[record] \u001B[38;5;241m=\u001B[39m \u001B[43meeg_io\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__copy__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;66;03m# deep copy info (for further modification)\u001B[39;00m\n\u001B[0;32m    529\u001B[0m result\u001B[38;5;241m.\u001B[39minfo \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\n",
      "File \u001B[1;32mG:\\EEG_TAC\\datasets\\utils.py:350\u001B[0m, in \u001B[0;36mEEGSignalIO.__copy__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    345\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    346\u001B[0m result\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\u001B[38;5;241m.\u001B[39mupdate({\n\u001B[0;32m    347\u001B[0m     k: v\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_io\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    349\u001B[0m })\n\u001B[1;32m--> 350\u001B[0m result\u001B[38;5;241m.\u001B[39m_io \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_io\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__copy__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mG:\\EEG_TAC\\datasets\\utils.py:221\u001B[0m, in \u001B[0;36mLMDBEEGSignalIO.__copy__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    216\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    217\u001B[0m result\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\u001B[38;5;241m.\u001B[39mupdate({\n\u001B[0;32m    218\u001B[0m     k: v\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_env\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    220\u001B[0m })\n\u001B[1;32m--> 221\u001B[0m result\u001B[38;5;241m.\u001B[39m_env \u001B[38;5;241m=\u001B[39m \u001B[43mlmdb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mmap_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mlock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mMemoryError\u001B[0m: ./processed_data/deap_arousal_512\\_record_0\\eeg: Not enough space"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method AutoreloadMagics.post_execute_hook of <IPython.extensions.autoreload.AutoreloadMagics object at 0x00000242D6741300>> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\eeg-env\\lib\\site-packages\\IPython\\extensions\\autoreload.py:713\u001B[0m, in \u001B[0;36mAutoreloadMagics.post_execute_hook\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost_execute_hook\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    712\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Cache the modification times of any modules imported in this execution\"\"\"\u001B[39;00m\n\u001B[1;32m--> 713\u001B[0m     newly_loaded_modules \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodules\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaded_modules\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m modname \u001B[38;5;129;01min\u001B[39;00m newly_loaded_modules:\n\u001B[0;32m    715\u001B[0m         _, pymtime \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reloader\u001B[38;5;241m.\u001B[39mfilename_and_mtime(sys\u001B[38;5;241m.\u001B[39mmodules[modname])\n",
      "\u001B[1;31mMemoryError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = build_model(args)\n",
    "\n",
    "logger.info(f\"Model: {args['model_name']}, Number of parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.4f} M\")\n",
    "for name, module in model.named_children():\n",
    "    total_params = sum(p.numel() for p in module.parameters()) / 1e6\n",
    "    logger.info(f\"{name}: {total_params:.4f}M\")\n",
    "                \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "final_results_dict = train_model_per_subject(model=model, dataset=dataset, optimizer=optimizer, cv=cv,\n",
    "                            subject_num=args['subject_num'], max_epochs=args['max_epochs'], \n",
    "                            batch_size=args['batch_size'], device=args['device'], logger=logger, log_dir=log_dir, sub_idx=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-09T16:11:45.309670Z",
     "end_time": "2025-05-09T16:11:50.832416Z"
    }
   },
   "outputs": [],
   "source": [
    "# the mean of all subjects\n",
    "final_results_csv_path = os.path.join(log_dir, 'all_subjects_mean_results.csv')\n",
    "filtered_results_csv_path = os.path.join(log_dir, 'filtered_subjects_mean_results.csv')\n",
    "\n",
    "save_result(final_results_dict, final_results_csv_path, filtered_results_csv_path, exclude_counts = None, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2025-05-09T16:15:43.216311Z",
     "end_time": "2025-05-09T16:15:43.469312Z"
    }
   },
   "outputs": [],
   "source": [
    "src_file = \"train_deap.ipynb\"\n",
    "dst = os.path.join(log_dir, src_file)\n",
    "        \n",
    "shutil.copy(src_file, dst)\n",
    "print(f\"File has saved into: {dst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-09T09:56:00.736891Z",
     "end_time": "2025-05-09T09:56:00.780888Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
